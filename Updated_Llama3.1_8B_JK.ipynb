{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Llama3_8B (N = 58166, whole)**"
      ],
      "metadata": {
        "id": "6dQ3RtqETthO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Prompt + parsing\n",
        "# -----------------------------\n",
        "SYSTEM_INSTRUCTION = \"\"\"You are a conservative clinical text rater.\n",
        "Do not diagnose; only label explicit depressive symptoms in the patient's words.\"\"\"\n",
        "\n",
        "USER_TEMPLATE = \"\"\"Task: Label depressive symptoms (1) vs not present (0) from the patient's message.\n",
        "Use only explicit evidence from the text. If uncertain, label 0.\n",
        "\n",
        "Depressive symptoms (label 1 only if explicitly present):\n",
        "- persistent sadness/depressed mood\n",
        "- hopelessness/worthlessness/guilt\n",
        "- loss of interest/pleasure (anhedonia)\n",
        "- suicidal ideation/self-harm (always 1)\n",
        "- explicit statements of inability to function due to mood (not due to pain/illness)\n",
        "\n",
        "Not depression (label 0):\n",
        "- appointment scheduling or cancellations\n",
        "- physical illness/pain without mood language\n",
        "- mild frustration without mood symptoms\n",
        "\n",
        "IMPORTANT: The following are examples that MUST be labeled 0:\n",
        "Example A message: \"Just took my temperature. 98.9. Bummer! I guess I'll lie low for today.\"\n",
        "Explanation: \"bummer\" + resting does NOT equal depression.\n",
        "Example B message: \"I can’t come on 4/8, so put me down for 4/20.\"\n",
        "Explanation: rescheduling does NOT indicate low motivation.\n",
        "Example C message: \"Doctor is aware that I am in acute pain ... MRI ... urgent care?\"\n",
        "Explanation: acute pain/medical urgency is physical distress, not depression.\n",
        "\n",
        "Output format (exactly):\n",
        "Classification: <0 or 1>\n",
        "Evidence: <quote exact phrase(s) supporting the label; if 0 write \"none\">\n",
        "Reason: <brief explanation tied to Evidence>\n",
        "Message:\n",
        "{text}\"\"\"\n",
        "\n",
        "# Tune for your workload\n",
        "BATCH_SIZE = 16\n",
        "MAX_NEW_TOKENS = 45\n",
        "TEMPERATURE = 0.0\n",
        "TOP_P = 0.9\n",
        "\n",
        "# Prompt truncation cap (match llama_local_batch_fn default unless you want different)\n",
        "MAX_PROMPT_LEN = 2048\n",
        "\n",
        "LOG_EVERY_BATCHES = 20\n",
        "SAVE_EVERY_BATCHES = 20\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def llama_local_batch_fn(\n",
        "    texts: List[str],\n",
        "    max_new_tokens: int = 64,\n",
        "    temperature: float = 0.0,\n",
        "    top_p: float = 0.9,\n",
        "    max_length: int = 2048,\n",
        "    return_raw: bool = False,\n",
        ") -> Tuple[List[int], List[str], Optional[List[str]]]:\n",
        "    messages_list = []\n",
        "    for t in texts:\n",
        "        user_prompt = USER_TEMPLATE.format(text=t)\n",
        "        messages_list.append([\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_INSTRUCTION},\n",
        "            {\"role\": \"user\", \"content\": user_prompt},\n",
        "        ])\n",
        "\n",
        "    prompts = [\n",
        "        tokenizer.apply_chat_template(m, tokenize=False, add_generation_prompt=True)\n",
        "        for m in messages_list\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompts,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "    ).to(model.device)\n",
        "\n",
        "    do_sample = temperature > 0.0\n",
        "\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=do_sample,\n",
        "        temperature=temperature if do_sample else None,\n",
        "        top_p=top_p if do_sample else None,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        use_cache=True,\n",
        "    )\n",
        "\n",
        "    prompt_lens = inputs[\"attention_mask\"].sum(dim=1).tolist()\n",
        "\n",
        "    classifications, reasons = [], []\n",
        "    completions = [] if return_raw else None\n",
        "\n",
        "    for i in range(out.shape[0]):\n",
        "        gen_ids = out[i, prompt_lens[i]:]\n",
        "        completion = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "        c, r = _parse_classification_and_reason(completion)\n",
        "        classifications.append(int(c) if c in (0, 1) else 0)\n",
        "        reasons.append((r or \"\").strip())\n",
        "        if return_raw:\n",
        "            completions.append(completion)\n",
        "\n",
        "    return classifications, reasons, completions\n",
        "\n"
      ],
      "metadata": {
        "id": "sjUgfMmjNxhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Accuracy computation**"
      ],
      "metadata": {
        "id": "dXdh7VheSAcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics_at_threshold(df, threshold, prevalence=0.25, eps=0.5):\n",
        "    required = {\"total_messages\", \"positive_messages\", \"label\"}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise KeyError(f\"Missing required columns: {sorted(missing)}\")\n",
        "\n",
        "    eligible = df.loc[df[\"total_messages\"] >= threshold].copy()\n",
        "    n_eligible = int(len(eligible))\n",
        "\n",
        "    if n_eligible == 0:\n",
        "        return {\n",
        "            \"threshold\": threshold,\n",
        "            \"n_eligible\": 0,\n",
        "            \"n_flagged\": 0,\n",
        "            \"tp\": 0, \"fp\": 0, \"fn\": 0, \"tn\": 0,\n",
        "            \"sensitivity\": np.nan,\n",
        "            \"specificity\": np.nan,\n",
        "            \"ppv_adj\": np.nan,\n",
        "            \"npv_adj\": np.nan,\n",
        "            \"odds_ratio\": np.nan,\n",
        "            \"or_ci_low\": np.nan,\n",
        "            \"or_ci_high\": np.nan,\n",
        "        }\n",
        "\n",
        "    y_true = eligible[\"label\"].astype(int).clip(0, 1)\n",
        "    y_pred = (eligible[\"positive_messages\"] >= threshold).astype(int)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "\n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) else np.nan\n",
        "    specificity = tn / (tn + fp) if (tn + fp) else np.nan\n",
        "\n",
        "    denom_ppv = sensitivity * prevalence + (1 - specificity) * (1 - prevalence)\n",
        "    ppv_adj = (sensitivity * prevalence) / denom_ppv if denom_ppv else np.nan\n",
        "\n",
        "    denom_npv = (1 - sensitivity) * prevalence + specificity * (1 - prevalence)\n",
        "    npv_adj = (specificity * (1 - prevalence)) / denom_npv if denom_npv else np.nan\n",
        "\n",
        "    tp_c, fp_c, fn_c, tn_c = tp + eps, fp + eps, fn + eps, tn + eps\n",
        "    odds_ratio = (tp_c * tn_c) / (fp_c * fn_c)\n",
        "\n",
        "    se_log_or = math.sqrt(1/tp_c + 1/fp_c + 1/fn_c + 1/tn_c)\n",
        "    or_ci_low = math.exp(math.log(odds_ratio) - 1.96 * se_log_or)\n",
        "    or_ci_high = math.exp(math.log(odds_ratio) + 1.96 * se_log_or)\n",
        "\n",
        "    return {\n",
        "        \"threshold\": int(threshold),\n",
        "        \"n_eligible\": n_eligible,\n",
        "        \"n_flagged\": int(y_pred.sum()),\n",
        "        \"tp\": int(tp), \"fp\": int(fp), \"fn\": int(fn), \"tn\": int(tn),\n",
        "        \"sensitivity\": sensitivity,\n",
        "        \"specificity\": specificity,\n",
        "        \"ppv_adj\": ppv_adj,\n",
        "        \"npv_adj\": npv_adj,\n",
        "        \"odds_ratio\": odds_ratio,\n",
        "        \"or_ci_low\": or_ci_low,\n",
        "        \"or_ci_high\": or_ci_high,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ysu5WRjSb14f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_t = int(patient_df[\"total_messages\"].max())\n",
        "\n",
        "results = [\n",
        "    compute_metrics_at_threshold(patient_df, t, prevalence=0.25)\n",
        "    for t in range(1, max_t + 1)\n",
        "]\n",
        "\n",
        "perf_df = pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "kOozC6FD2KtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Staged screening analysis**"
      ],
      "metadata": {
        "id": "MY2n4yZGwEvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional, Dict, Any\n",
        "\n",
        "def compute_stage2_lead_time(df_msg: pd.DataFrame, t2: int, id_col: str = \"a_id\") -> pd.DataFrame:\n",
        "    d = df_msg.copy()\n",
        "    d[\"created_time\"] = pd.to_datetime(d[\"created_time\"])\n",
        "    d[\"dep_start\"] = pd.to_datetime(d[\"dep_start\"])\n",
        "\n",
        "    # Restrict to cases\n",
        "    d = d[d[\"label\"] == 1].copy()\n",
        "\n",
        "    d[\"flag_msg\"] = (d[\"predictions\"] == 1).astype(int)\n",
        "    d = d.sort_values([id_col, \"created_time\"])\n",
        "    d[\"cum_pos\"] = d.groupby(id_col)[\"flag_msg\"].cumsum()\n",
        "\n",
        "    reach = (\n",
        "        d.loc[d[\"cum_pos\"] >= t2]\n",
        "         .groupby(id_col, as_index=False)\n",
        "         .first()[[id_col, \"created_time\"]]\n",
        "         .rename(columns={\"created_time\": \"reach_date_t2\"})\n",
        "    )\n",
        "\n",
        "    dx = (\n",
        "        d.groupby(id_col, as_index=False)[\"dep_start\"]\n",
        "         .first()\n",
        "         .rename(columns={\"dep_start\": \"dx_date\"})\n",
        "    )\n",
        "\n",
        "    out = dx.merge(reach, on=id_col, how=\"left\")\n",
        "    out[\"days_earlier_t2\"] = (out[\"dx_date\"] - out[\"reach_date_t2\"]).dt.days\n",
        "    return out\n",
        "\n",
        "\n",
        "def staged_metrics_eligible(\n",
        "    person_df: pd.DataFrame,\n",
        "    t1: int = 1,\n",
        "    t2: int = 30,\n",
        "    df_msg_for_lead: Optional[pd.DataFrame] = None,\n",
        "    id_col: str = \"a_id\",\n",
        "    total_msg_col: str = \"total_messages\",\n",
        "    require_pre_dx_msgs_for_lead: bool = False,\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    dfp =person_df.copy()\n",
        "\n",
        "    for col in [id_col, total_msg_col, \"positive_messages\", \"label\"]:\n",
        "        if col not in dfp.columns:\n",
        "            raise ValueError(f\"Missing required column in person_df: '{col}'\")\n",
        "\n",
        "    eligible = dfp[dfp[total_msg_col] >= t2].copy()\n",
        "\n",
        "    if len(eligible) == 0:\n",
        "        return {\n",
        "            \"t1\": t1, \"t2\": t2,\n",
        "            \"n_eligible\": 0,\n",
        "            \"n_monitored\": 0, \"n_escalated\": 0,\n",
        "            \"n_monitored_cases\": 0, \"n_monitored_controls\": 0,\n",
        "            \"n_escalated_cases\": 0, \"n_escalated_controls\": 0,\n",
        "            \"escalation_overall\": np.nan,\n",
        "            \"escalation_cases\": np.nan,\n",
        "            \"escalation_controls\": np.nan,\n",
        "            \"ppv_stage2\": np.nan,\n",
        "            \"n_cases_with_lead_time_t2\": 0,\n",
        "            \"median_days_earlier_t2\": np.nan,\n",
        "        }\n",
        "\n",
        "    eligible[\"stage1\"] = (eligible[\"positive_messages\"] >= t1).astype(int)\n",
        "    monitored = eligible[eligible[\"stage1\"] == 1].copy()\n",
        "\n",
        "    monitored[\"stage2\"] = (monitored[\"positive_messages\"] >= t2).astype(int)\n",
        "    escalated = monitored[monitored[\"stage2\"] == 1].copy()\n",
        "\n",
        "    n_monitored = len(monitored)\n",
        "    n_escalated = len(escalated)\n",
        "\n",
        "    escalation_overall = n_escalated / n_monitored if n_monitored else np.nan\n",
        "\n",
        "    mon_cases = monitored[monitored[\"label\"] == 1]\n",
        "    mon_controls = monitored[monitored[\"label\"] == 0]\n",
        "    esc_cases = escalated[escalated[\"label\"] == 1]\n",
        "    esc_controls = escalated[escalated[\"label\"] == 0]\n",
        "\n",
        "    escalation_cases = len(esc_cases) / len(mon_cases) if len(mon_cases) else np.nan\n",
        "    escalation_controls = len(esc_controls) / len(mon_controls) if len(mon_controls) else np.nan\n",
        "\n",
        "    ppv_stage2 = escalated[\"label\"].mean() if n_escalated else np.nan\n",
        "\n",
        "    median_days_earlier_t2 = np.nan\n",
        "    n_cases_reached_t2_pre_dx = 0\n",
        "\n",
        "    if df_msg_for_lead is not None and len(esc_cases):\n",
        "        for col in [id_col, \"created_time\", \"dep_start\", \"label\", \"predictions\"]:\n",
        "            if col not in df_msg_for_lead.columns:\n",
        "                raise ValueError(f\"Missing required column in df_msg_for_lead: '{col}'\")\n",
        "\n",
        "        lead_tbl = compute_stage2_lead_time(df_msg_for_lead, t2=t2, id_col=id_col)\n",
        "\n",
        "        esc_case_ids = set(esc_cases[id_col].unique())\n",
        "        lead_tbl = lead_tbl[lead_tbl[id_col].isin(esc_case_ids)].copy()\n",
        "\n",
        "        lead_tbl = lead_tbl.dropna(subset=[\"days_earlier_t2\"])\n",
        "        lead_tbl = lead_tbl[lead_tbl[\"days_earlier_t2\"] >= 0]\n",
        "\n",
        "        if require_pre_dx_msgs_for_lead:\n",
        "            d = df_msg_for_lead.copy()\n",
        "            d[\"created_time\"] = pd.to_datetime(d[\"created_time\"])\n",
        "            d[\"dep_start\"] = pd.to_datetime(d[\"dep_start\"])\n",
        "            d = d[d[\"label\"] == 1].copy()\n",
        "\n",
        "            pre_dx_counts = (\n",
        "                d[d[\"created_time\"] <= d[\"dep_start\"]]\n",
        "                .groupby(id_col)\n",
        "                .size()\n",
        "                .rename(\"pre_dx_total_messages\")\n",
        "                .reset_index()\n",
        "            )\n",
        "\n",
        "            lead_tbl = lead_tbl.merge(pre_dx_counts, on=id_col, how=\"left\")\n",
        "            lead_tbl[\"pre_dx_total_messages\"] = lead_tbl[\"pre_dx_total_messages\"].fillna(0).astype(int)\n",
        "            lead_tbl = lead_tbl[lead_tbl[\"pre_dx_total_messages\"] >= t2]\n",
        "\n",
        "        n_cases_reached_t2_pre_dx = len(lead_tbl)\n",
        "        if n_cases_reached_t2_pre_dx:\n",
        "            median_days_earlier_t2 = float(lead_tbl[\"days_earlier_t2\"].median())\n",
        "\n",
        "    return {\n",
        "        \"t1\": t1,\n",
        "        \"t2\": t2,\n",
        "        \"n_eligible\": int(len(eligible)),\n",
        "        \"ppv_stage2\": float(ppv_stage2) if ppv_stage2 == ppv_stage2 else np.nan,\n",
        "        \"n_cases_with_lead_time_t2\": int(n_cases_reached_t2_pre_dx),\n",
        "        \"median_days_earlier_t2\": median_days_earlier_t2,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "zP7-cOgxcRlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_5azEPsdVLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Message-level (message-volume adjusted = **exposure-adjusted) performmance**"
      ],
      "metadata": {
        "id": "AkRhn84-R3n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.proportion import proportion_confint\n",
        "import numpy as np\n",
        "\n",
        "# Counts\n",
        "TP = ((comb[\"predictions\"] == 1) & (comb[\"label\"] == 1)).sum()\n",
        "FN = ((comb[\"predictions\"] == 0) & (comb[\"label\"] == 1)).sum()\n",
        "FP = ((comb[\"predictions\"] == 1) & (comb[\"label\"] == 0)).sum()\n",
        "TN = ((comb[\"predictions\"] == 0) & (comb[\"label\"] == 0)).sum()\n",
        "\n",
        "# Point estimates\n",
        "sensitivity = TP / (TP + FN) if (TP + FN) > 0 else np.nan\n",
        "specificity = TN / (TN + FP) if (TN + FP) > 0 else np.nan\n",
        "PPV = TP / (TP + FP) if (TP + FP) > 0 else np.nan\n",
        "NPV = TN / (TN + FN) if (TN + FN) > 0 else np.nan\n",
        "\n",
        "# Wilson 95% CI for sensitivity and specificity\n",
        "sens_ci_low, sens_ci_high = (\n",
        "    proportion_confint(TP, TP + FN, alpha=0.05, method=\"wilson\")\n",
        "    if (TP + FN) > 0 else (np.nan, np.nan)\n",
        ")\n",
        "spec_ci_low, spec_ci_high = (\n",
        "    proportion_confint(TN, TN + FP, alpha=0.05, method=\"wilson\")\n",
        "    if (TN + FP) > 0 else (np.nan, np.nan)\n",
        ")\n",
        "\n",
        "# Odds ratio + Woolf CI (with continuity correction if needed)\n",
        "cells = np.array([TP, FP, FN, TN], dtype=float)\n",
        "use_cc = np.any(cells == 0)\n",
        "\n",
        "TPc, FPc, FNc, TNc = (cells + 0.5) if use_cc else cells  # Haldane–Anscombe correction\n",
        "\n",
        "odds_ratio = (TPc * TNc) / (FPc * FNc)\n",
        "se_log_or = np.sqrt(1/TPc + 1/TNc + 1/FPc + 1/FNc)\n",
        "log_or = np.log(odds_ratio)\n",
        "ci_lower = np.exp(log_or - 1.96 * se_log_or)\n",
        "ci_upper = np.exp(log_or + 1.96 * se_log_or)\n",
        "\n",
        "print(f\"Sensitivity: {sensitivity:.4f} (95% CI {sens_ci_low:.4f}–{sens_ci_high:.4f})\")\n",
        "print(f\"Specificity: {specificity:.4f} (95% CI {spec_ci_low:.4f}–{spec_ci_high:.4f})\")\n",
        "print(f\"PPV: {PPV:.4f}\")\n",
        "print(f\"NPV: {NPV:.4f}\")\n",
        "print(f\"Odds Ratio: {odds_ratio:.4f} (95% CI {ci_lower:.4f}–{ci_upper:.4f})\"\n",
        "      + (\" [continuity-corrected]\" if use_cc else \"\"))\n"
      ],
      "metadata": {
        "id": "_XVzadEBSAJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Performance by time window**"
      ],
      "metadata": {
        "id": "9hMfSlwwMwhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def days_earlier_by_threshold(df: pd.DataFrame, t: int, id_col: str = \"a_id\") -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df[\"created_time\"] = pd.to_datetime(df[\"created_time\"])\n",
        "    df[\"dep_start\"] = pd.to_datetime(df[\"dep_start\"])\n",
        "\n",
        "    cases = df[df[\"label\"] == 1].copy()\n",
        "    cases[\"flag_msg\"] = (cases[\"predictions\"] == 1).astype(int)\n",
        "\n",
        "    cases = cases.sort_values([id_col, \"created_time\"])\n",
        "    cases[\"cum_pos\"] = cases.groupby(id_col)[\"flag_msg\"].cumsum()\n",
        "\n",
        "    reach = (\n",
        "        cases.loc[cases[\"cum_pos\"] >= t]\n",
        "            .groupby(id_col, as_index=False)\n",
        "            .first()[[id_col, \"created_time\"]]\n",
        "            .rename(columns={\"created_time\": \"reach_date\"})\n",
        "    )\n",
        "\n",
        "    dx = (\n",
        "        cases.groupby(id_col, as_index=False)[\"dep_start\"]\n",
        "            .first()\n",
        "            .rename(columns={\"dep_start\": \"dx_date\"})\n",
        "    )\n",
        "\n",
        "    out = dx.merge(reach, on=id_col, how=\"left\")\n",
        "    out[\"days_earlier\"] = (out[\"dx_date\"] - out[\"reach_date\"]).dt.days\n",
        "    return out\n",
        "\n",
        "early_t5 = days_earlier_by_threshold(df, t=5)\n",
        "\n",
        "flagged_t5 = early_t5.dropna(subset=[\"days_earlier\"]).copy()\n",
        "flagged_t5 = flagged_t5[flagged_t5[\"days_earlier\"] >= 0]  # reached before diagnosis\n",
        "summary = flagged_t5[\"days_earlier\"].describe()\n",
        "print(summary)\n"
      ],
      "metadata": {
        "id": "TZFtOE7SMbqX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "npjDM_MSG_Rev_Llama3.1_8B_FULL_Git_JK.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}